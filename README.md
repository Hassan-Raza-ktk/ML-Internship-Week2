# ML Internship - Week 2: Data Handling with NumPy & Pandas

This repository contains the tasks completed during the second week of my Machine Learning internship.

## Project Structure
- **Task_2_1_Numpy/**: Exercises covering NumPy basics, arrays, and mathematical operations.
- **Task_2_2_Pandas/**: Comprehensive data cleaning and exploration on the Titanic dataset.
- **screenshots/**: Proof of environment setup and code execution.

## Tech Stack
- **Python**
- **NumPy** (for numerical computations)
- **Pandas** (for data manipulation)
- **Matplotlib/Seaborn** (for data visualization)

## Key Learning Outcomes
1. Data cleaning techniques (handling missing values, encoding).
2. Efficient array processing using NumPy.
3. Feature engineering and data visualization.

## Task 2.3 â€“ Data Visualization with Matplotlib & Seaborn

In this task, I used the cleaned Titanic dataset to create multiple data visualizations for better exploratory data analysis.

### Visualizations Created
- Line plot (Age distribution)
- Scatter plot (Age vs Fare)
- Histogram (Passenger class distribution)
- Bar chart (Survival rates)
- Box plot (Fare by passenger class)
- Violin plot (Age by gender)
- Correlation heatmap
- Pair plot for numerical features

- Below are some example visualizations generated in Task 2.3:
<img src="Task_2_3_Visualization/visualizations/line_plot.png" width="400" alt="Age Distribution">

<img src="Task_2_3_Visualization/visualizations/bar_chart.png" width="400" alt="Survival Rates">

<img src="Task_2_3_Visualization/visualizations/heatmap.png" width="400" alt="Correlation Heatmap">

Other plots (scatter, box, violin, pair plot) are available in the visualizations folder.

All visualizations were generated using **Matplotlib and Seaborn** and saved as PNG files.

### Key Learnings
- Choosing appropriate plots for different data types
- Understanding relationships between numerical features
- Visual interpretation of survival patterns in the Titanic dataset

## Task 2.4: Object-Oriented Programming (OOP) for ML
Task_2_4_OOP/: Modularized data preprocessing using Python Classes.

**data_preprocessor.py:** A complete class-based script for automated data handling.

**final_processed_data.csv:** The final cleaned and scaled dataset generated by the script.

## Key Implementation:
**Encapsulation:** Wrapped all preprocessing steps (loading, cleaning, scaling) inside a reusable DataPreprocessor class.

**Feature Encoding:** Categorical variables (Sex, Embarked) converted into numerical format using Label Encoding.

**Feature Scaling:** Applied StandardScaler to Age and Fare to normalize the data range.

**Data Export:** Implemented save_processed_data() to export the final dataset for future model training.

**Train-Test Split:** Divided the data into 80% Training and 20% Testing sets.

*Created by [Hassan Raza]*
